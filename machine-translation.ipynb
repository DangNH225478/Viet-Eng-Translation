{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":10881188,"sourceType":"datasetVersion","datasetId":6761122},{"sourceId":10881313,"sourceType":"datasetVersion","datasetId":6761215}],"dockerImageVersionId":30920,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\ndef load_embedding(emb_path, emb_dim = 300):\n    embeddings={}\n    with open(emb_path, \"r\",encoding='utf-8') as f:\n        for line in f:    \n            values=line.strip().split()\n            word=values[0]\n            vector=np.asarray(values[1:], dtype=np.float32)\n            if len(vector)==emb_dim:\n                embeddings[word]=vector\n    return embeddings\nvi_emb=load_embedding(\"/kaggle/input/embedding/cc.vi.300.vec\", emb_dim=300)\nen_emb=load_embedding(\"/kaggle/input/embedding/cc.vi.300.vec\", emb_dim=300)\n\nprint(vi_emb.get(\"xin\", \"Not found\"))\nprint(en_emb.get(\"hello\", \"Not found\"))\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-03-01T12:10:32.471549Z","iopub.execute_input":"2025-03-01T12:10:32.471874Z","iopub.status.idle":"2025-03-01T12:14:44.867805Z","shell.execute_reply.started":"2025-03-01T12:10:32.471839Z","shell.execute_reply":"2025-03-01T12:14:44.867074Z"}},"outputs":[{"name":"stdout","text":"[-0.0773  0.0038  0.2197  0.0483 -0.0276 -0.0284  0.0559 -0.0435  0.0486\n  0.0483 -0.1832 -0.0886  0.037   0.0301 -0.2261  0.2115  0.0942  0.1687\n  0.0144 -0.078  -0.0376 -0.0617  0.041  -0.0558  0.1403 -0.1129 -0.0191\n -0.1314  0.0698  0.1036 -0.1541 -0.1535  0.0891 -0.0012 -0.0125  0.1032\n -0.0274 -0.0043  0.0149 -0.1026  0.024   0.0583  0.0162  0.0269 -0.0778\n -0.0694 -0.0035 -0.0453 -0.0755 -0.0589  0.1125  0.1777 -0.2076  0.054\n -0.0712 -0.2649 -0.0561 -0.0493 -0.09    0.0517  0.1251 -0.0806 -0.083\n -0.2259  0.0186 -0.0627 -0.0883 -0.0049  0.1506 -0.0081  0.0632 -0.0183\n -0.0592 -0.204   0.0016 -0.044  -0.1258  0.0098  0.0485 -0.0206 -0.25\n  0.0724 -0.0894  0.0792 -0.2011  0.0731 -0.0675  0.0333  0.1101  0.1286\n  0.0445 -0.2718 -0.1094  0.0372  0.0687 -0.0385  0.0642 -0.0129 -0.0773\n  0.0529 -0.0212 -0.0278  0.0197 -0.1464  0.0162 -0.2767  0.0146  0.1724\n -0.0102 -0.036  -0.1316 -0.0276  0.0529 -0.0365 -0.0197 -0.0526 -0.0369\n -0.069   0.0169 -0.1916  0.0019  0.0583  0.0873  0.0943 -0.045  -0.0388\n -0.0392 -0.1402  0.0441  0.0622  0.0087 -0.1017 -0.1325 -0.0887  0.0204\n -0.1504  0.1836  0.2097  0.0658 -0.0115 -0.031   0.0473 -0.204  -0.1699\n  0.0078  0.2245  0.0968 -0.0744  0.0712 -0.029   0.0197 -0.0264  0.0652\n -0.0397  0.0862 -0.0086  0.1994  0.0494  0.0409 -0.0208  0.0385 -0.0677\n -0.0348  0.0026 -0.0348  0.19   -0.017   0.0048  0.0234 -0.1825 -0.0044\n -0.02   -0.053  -0.0406 -0.0612  0.0572  0.0303  0.0856  0.1068 -0.0106\n -0.0772  0.0125  0.1165 -0.0411  0.3456 -0.1224 -0.2392 -0.0197 -0.0557\n -0.075  -0.1172  0.013  -0.0116  0.0022 -0.0242  0.0969 -0.1912  0.0703\n  0.2531 -0.089  -0.0081 -0.0623 -0.0585 -0.1262 -0.0118 -0.0339  0.1199\n  0.0068 -0.0833 -0.0024 -0.0754 -0.1565  0.1575 -0.0159  0.0524  0.0903\n  0.0593  0.1059  0.0731  0.069  -0.0257  0.031   0.1213  0.0188 -0.0068\n -0.0487 -0.0188 -0.0593  0.1364  0.0575  0.0063 -0.0688  0.0661 -0.0367\n -0.0515 -0.0188  0.0603  0.005  -0.027  -0.075   0.039  -0.0481  0.061\n -0.0184  0.0741  0.0349 -0.0495 -0.1844 -0.0694  0.0679 -0.0473 -0.0713\n -0.094  -0.0842  0.1976 -0.0028 -0.0377  0.2634 -0.0509  0.0583 -0.0449\n -0.0319 -0.068   0.0705 -0.0959 -0.1285  0.0504 -0.1416  0.0562  0.0137\n -0.1123  0.0084  0.0063  0.0966 -0.0586  0.0374  0.0097 -0.0841  0.0521\n  0.0052  0.0972 -0.      0.1419 -0.0518 -0.0522  0.0214  0.0308 -0.258\n  0.0146  0.0035  0.1276  0.0045  0.0739 -0.0563 -0.1082 -0.1171  0.2823\n -0.0308 -0.0567  0.013 ]\n[ 5.940e-02 -2.720e-02 -6.030e-02 -6.110e-02 -1.144e-01 -5.180e-02\n -3.700e-02 -8.300e-03 -2.140e-02  3.700e-03 -1.165e-01 -3.470e-02\n -4.000e-02  5.560e-02  3.980e-02  6.700e-03  3.590e-02 -3.450e-02\n -3.170e-02  4.720e-02 -9.600e-02  7.390e-02 -1.000e-04  4.690e-02\n -6.300e-02 -1.411e-01 -7.340e-02  2.020e-02 -8.040e-02  6.600e-02\n -6.500e-03 -9.700e-03  5.230e-02 -5.960e-02 -6.390e-02  9.300e-02\n -1.080e-02 -7.760e-02 -4.580e-02  4.920e-02 -3.700e-03  3.190e-02\n  2.330e-02  3.790e-02  1.060e-02 -6.300e-02  2.790e-02 -8.610e-02\n -4.770e-02 -4.510e-02  6.050e-02  9.320e-02  1.660e-02 -9.660e-02\n -5.400e-03 -7.850e-02 -8.610e-02  1.588e-01 -8.140e-02 -4.470e-02\n  7.490e-02 -6.260e-02 -6.520e-02  1.070e-02 -1.650e-02  1.070e-01\n -1.500e-03 -3.520e-02  3.560e-02  4.870e-02 -6.300e-02  5.900e-02\n -2.930e-02  1.160e-02  2.800e-02 -5.560e-02 -2.440e-02 -6.280e-02\n -1.257e-01  1.367e-01  2.870e-02 -2.510e-02 -4.100e-03 -3.600e-03\n -1.779e-01  2.920e-02 -1.487e-01 -1.250e-02  3.820e-02 -1.440e-02\n  6.390e-02  8.850e-02  5.350e-02 -4.810e-02  2.660e-02  1.333e-01\n  2.830e-02 -5.360e-02  4.360e-02 -3.990e-02  3.180e-02  4.310e-02\n  4.720e-02 -9.300e-03 -3.300e-03 -6.040e-02  1.185e-01  8.520e-02\n -6.530e-02 -3.400e-03 -8.330e-02 -5.300e-03  3.290e-02 -4.510e-02\n  8.060e-02  2.100e-02 -1.270e-02  5.300e-03 -1.177e-01 -4.790e-02\n -4.330e-02 -1.445e-01  4.040e-02  6.980e-02  7.740e-02  1.690e-02\n  4.640e-02 -2.710e-02  1.015e-01  2.196e-01 -1.053e-01  1.520e-02\n -7.720e-02 -1.460e-02 -5.610e-02 -8.020e-02  1.099e-01  1.140e-02\n  3.440e-02  8.090e-02 -4.210e-02 -3.100e-02  7.920e-02 -4.960e-02\n -9.220e-02  5.380e-02  1.415e-01  2.110e-02  4.960e-02  3.560e-02\n  3.440e-02 -2.820e-02 -6.510e-02 -4.580e-02 -8.150e-02  1.700e-02\n  4.250e-02 -1.000e-04  4.920e-02  1.810e-02 -2.450e-02  5.590e-02\n  8.570e-02  6.600e-03 -6.240e-02  2.025e-01  2.950e-02  8.200e-03\n  5.300e-02 -6.430e-02  9.400e-03  5.120e-02  5.530e-02  2.700e-03\n -8.460e-02 -1.102e-01  9.790e-02 -7.180e-02  1.381e-01 -5.400e-02\n  1.168e-01 -4.860e-02  7.000e-04 -2.020e-02  5.760e-02  1.194e-01\n -6.090e-02  9.150e-02 -1.680e-02  5.800e-02 -4.440e-02 -2.940e-02\n -2.870e-02  6.280e-02 -3.950e-02  4.530e-02 -5.280e-02  5.330e-02\n -4.930e-02 -6.470e-02  1.464e-01  8.890e-02  1.213e-01 -1.420e-02\n -3.230e-02 -6.770e-02  1.510e-01  2.140e-02 -1.029e-01 -1.435e-01\n  1.181e-01  4.540e-02  1.584e-01  4.000e-02 -5.670e-02  6.090e-02\n -2.020e-02 -1.900e-03 -2.280e-02 -1.291e-01 -4.500e-02 -5.800e-03\n -7.910e-02 -9.700e-02 -5.920e-02  2.200e-03 -2.570e-02  3.110e-02\n  4.800e-02 -5.440e-02  1.000e-03 -1.080e-02  1.192e-01 -3.170e-02\n -1.444e-01 -5.200e-02  1.492e-01 -2.800e-02  1.151e-01 -8.600e-03\n -6.470e-02 -1.490e-02  6.410e-02 -1.072e-01  9.580e-02  1.110e-02\n -2.860e-02 -9.480e-02 -6.630e-02 -8.070e-02  6.390e-02  5.980e-02\n  6.840e-02  2.130e-02  3.710e-02  2.540e-02  6.890e-02  2.150e-02\n  9.520e-02 -1.020e-02 -4.050e-02  4.000e-02  3.700e-02 -2.750e-02\n  8.100e-02  6.430e-02 -5.970e-02 -1.050e-02 -1.340e-02  3.400e-02\n -1.020e-02 -8.040e-02  1.112e-01 -6.820e-02 -8.400e-03  2.770e-02\n -1.408e-01  2.000e-03 -2.700e-03  5.630e-02  5.100e-03  7.800e-02\n  7.500e-02  6.820e-02  3.570e-02  2.800e-03  1.693e-01 -1.000e-02\n  2.330e-02  2.490e-02  9.100e-03  5.400e-02  3.140e-02 -9.590e-02\n  6.100e-03 -6.400e-03  1.054e-01  1.165e-01  5.700e-03 -5.910e-02]\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"def load_dataset(vi_path, en_path):\n    vi_sentences=[]\n    en_sentences=[]\n    with open(vi_path, \"r\",encoding='utf-8') as f:\n        for line in f:\n            vi_sentences.append(line.strip().split())\n    with open(en_path, \"r\",encoding='utf-8') as f:\n        for line in f:\n            en_sentences.append(line.strip().split())\n    return vi_sentences, en_sentences\nvi_train, en_train = load_dataset(\"/kaggle/input/phomtdataset/PhoMT/tokenization/train/train.vi\", \"/kaggle/input/phomtdataset/PhoMT/tokenization/train/train.en\")\nvi_val, en_val = load_dataset(\"/kaggle/input/phomtdataset/PhoMT/tokenization/dev/dev.vi\", \"/kaggle/input/phomtdataset/PhoMT/tokenization/dev/dev.en\")\nvi_test, en_test = load_dataset(\"/kaggle/input/phomtdataset/PhoMT/tokenization/test/test.vi\", \"/kaggle/input/phomtdataset/PhoMT/tokenization/test/test.en\")\n\nprint(vi_train[:2])\nprint(en_train[:2])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from collections import Counter\ndef build_vocab(sentences, min_freq=3, specials=[\"<oes>\", \"<pad>\", \"<sos>\", \"<unk>\"]):\n    word_counter=Counter(word for sent in sentences for word in sent)\n    vocab = {word: idx for idx, word in enumerate(specials)}\n    for word, count in word_counter.items():\n        if count >= min_freq: \n            vocab[word] = len(vocab)\n    return vocab\nvi_vocab = build_vocab(vi_train, min_freq=3)\nen_vocab = build_vocab(en_train, min_freq=3)\n\ndef sentence_to_indices(sentence, vocab):\n    return [vocab.get(word, vocab[\"<unk>\"]) for word in sentence]\n\nvi_data_indices = [sentence_to_indices(sent, vi_vocab) for sent in vi_train]\nen_data_indices = [sentence_to_indices(sent, en_vocab) for sent in en_train]\n\nprint(vi_data_indices[:2])\nprint(en_data_indices[:2])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import DataLoader, Dataset\nimport torch.nn.utils.rnn as rnn_utils\n\nclass TranslationDataset(Dataset):\n    def __init__(self, vi_data, en_data):\n        self.vi_data = vi_data\n        self.en_data = en_data\n\n    def __len__(self):\n        return len(self.vi_data)\n\n    def __getitem__(self, idx):\n        return torch.tensor(self.vi_data[idx]), torch.tensor(self.en_data[idx])\n\ndef collate_fn(batch):\n    vi_batch, en_batch = zip(*batch)\n    vi_batch = rnn_utils.pad_sequence(vi_batch, batch_first=True, padding_value=vi_vocab[\"<pad>\"])\n    en_batch = rnn_utils.pad_sequence(en_batch, batch_first=True, padding_value=en_vocab[\"<pad>\"])\n    return vi_batch, en_batch\n\ntrain_dataset = TranslationDataset(vi_data_indices, en_data_indices)\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, collate_fn=collate_fn)\n\nvi_batch, en_batch = next(iter(train_loader))\nprint(vi_batch.shape, en_batch.shape)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def emb_matrix(vocab, embeddings_dict, embedding_dim=300):\n    matrix = torch.randn(len(vocab), embedding_dim) \n    pad_idx = vocab[\"<pad>\"]\n    matrix[pad_idx] = torch.zeros(embedding_dim)\n    for word, idx in vocab.items():\n        if word in embeddings_dict:\n            matrix[idx] = torch.tensor(embeddings_dict[word], dtype=torch.float32)\n    return matrix\nvi_embedding_matrix = emb_matrix(vi_vocab, vi_emb, embedding_dim=300)\nen_embedding_matrix = emb_matrix(en_vocab, en_emb, embedding_dim=300)\n\nprint(vi_embedding_matrix.shape) \nprint(en_embedding_matrix.shape) ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nfrom tqdm import tqdm  \n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nclass TranslationDataset(Dataset):\n    def __init__(self, vi_sentences, en_sentences, vi_emb, en_emb, pad_idx, max_len=50):\n        self.vi_sentences = vi_sentences\n        self.en_sentences = en_sentences\n        self.vi_emb = vi_emb\n        self.en_emb = en_emb\n        self.pad_idx = pad_idx\n        self.max_len = max_len\n\n    def __len__(self):\n        return len(self.vi_sentences)\n    \n    def sentence_to_tensor(self, sentence, emb):\n        vectors = [torch.tensor(emb[word], dtype=torch.float32) if word in emb else torch.zeros(300) for word in sentence]\n        tensor = torch.stack(vectors)\n        if tensor.shape[0] < self.max_len:\n            pad_size = self.max_len - tensor.shape[0]\n            tensor = F.pad(tensor, (0, 0, 0, pad_size))\n        else:\n            tensor = tensor[:self.max_len]\n        return tensor\n\n    def __getitem__(self, idx):\n        vi_tensor = self.sentence_to_tensor(self.vi_sentences[idx], self.vi_emb)\n        en_tensor = self.sentence_to_tensor(self.en_sentences[idx], self.en_emb)\n        return vi_tensor, en_tensor\n\nclass TransformerModel(nn.Module):\n    def __init__(self, emb_dim=300, num_heads=6, num_layers=6, hidden_dim=512):\n        super().__init__()\n        self.encoder_layer = nn.TransformerEncoderLayer(\n            d_model=emb_dim, nhead=num_heads, dim_feedforward=hidden_dim, batch_first=True\n        )  \n        self.encoder = nn.TransformerEncoder(self.encoder_layer, num_layers=num_layers)\n        self.decoder_layer = nn.TransformerDecoderLayer(\n            d_model=emb_dim, nhead=num_heads, dim_feedforward=hidden_dim, batch_first=True\n        )\n        self.decoder = nn.TransformerDecoder(self.decoder_layer, num_layers=num_layers)\n        self.output_layer = nn.Linear(emb_dim, emb_dim)\n    \n    def forward(self, src, tgt):\n        memory = self.encoder(src)\n        output = self.decoder(tgt, memory)\n        return self.output_layer(output)\n\ndef train_model(model, dataloader, optimizer, criterion, device, num_epochs=10):\n    model.train()\n    for epoch in range(num_epochs):\n        total_loss = 0\n        loop = tqdm(dataloader, desc=f\"Epoch {epoch+1}/{num_epochs}\", leave=True)\n        for vi_tensor, en_tensor in loop:\n            vi_tensor = vi_tensor.to(device, non_blocking=True)\n            en_tensor = en_tensor.to(device, non_blocking=True) \n            optimizer.zero_grad()\n            output = model(vi_tensor, en_tensor)\n            loss = criterion(output, en_tensor)\n            loss.backward()\n            optimizer.step()\n            total_loss += loss.item()\n            loop.set_postfix(loss=total_loss / len(dataloader))\n        print(f\"Epoch {epoch+1}, Loss: {total_loss/len(dataloader):.4f}\")\ntrain_dataset = TranslationDataset(vi_train, en_train, vi_emb, en_emb, pad_idx=0)\ntrain_loader = DataLoader(\n    train_dataset, batch_size=16, shuffle=True, num_workers=2, pin_memory=True\n) \nmodel = TransformerModel().to(device)\ncriterion = nn.MSELoss()\noptimizer = optim.Adam(model.parameters(), lr=0.001)\ntrain_model(model, train_loader, optimizer, criterion, device)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}